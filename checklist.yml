---
- name: preflight checklist
  hosts: all
  any_errors_fatal: true
  tasks:
    - name: check if nodes have enough vcpus.
      ansible.builtin.assert:
        quiet: "{{ checklist.quiet }}"
        fail_msg: >-
          {{ inventory_hostname }} does not have enough vcpus.
          ({{ ansible_facts['processor_vcpus'] }} < {{ min_vcpus }})
        that:
          - ansible_facts['processor_vcpus'] >= min_vcpus

    - name: check if nodes have enough memory.
      ansible.builtin.assert:
        quiet: "{{ checklist.quiet }}"
        fail_msg: >-
          {{ inventory_hostname }} does not have enough memory.
          ({{ ansible_facts['memtotal_mb'] }} < {{ min_memory*1024*0.9 }})
        that:
          - ansible_facts['memtotal_mb'] >= (min_memory*1024*0.9)

    - name: check if nodes have enough root filesystem size.
      ansible.builtin.assert:
        quiet: "{{ checklist.quiet }}"
        fail_msg: >-
          {{ inventory_hostname }} does not have enough root filesystem.
          ({{ (ansible_facts['mounts']|selectattr("mount", "equalto", "/")|list)[0].size_total }} < {{ min_disk*(1024|pow(3))*0.9 }})
        that:
          - (ansible_facts['mounts']|selectattr("mount", "equalto", "/")|list)[0].size_total >= (min_disk*(1024|pow(3))*0.9)

    - name: touch /etc/resolv.conf on every node
      ansible.builtin.file:
        path: /etc/resolv.conf
        state: touch
      become: true

    - name: check if ip addresses in inventory hosts are valid.
      ansible.builtin.assert:
        quiet: "{{ checklist.quiet }}"
        fail_msg: >-
          {{ hostvars[inventory_hostname]['ip'] }} is not a valid ip address.
        that:
          - (hostvars[inventory_hostname]['ip']|ansible.builtin.ipaddr) != False

    - name: check if there is a default gateway on k8s nodes.
      ansible.builtin.assert:
        quiet: "{{ checklist.quiet }}"
        fail_msg: >-
          {{ inventory_hostname }} does not have a default gateway.
        that:
          - hostvars[inventory_hostname]['ansible_default_ipv4'].gateway is defined
      when:
        - inventory_hostname in groups['k8s_cluster']

    - name: check if keepalived_vip address is valid.
      ansible.builtin.assert:
        quiet: "{{ checklist.quiet }}"
        fail_msg: >-
          {{ keepalived_vip }} is not a valid ip address.
        that:
          - (keepalived_vip|ansible.builtin.ipaddr) != False
      delegate_to: localhost
      run_once: true

    - name: check if keepalived_vip_svc address is valid.
      ansible.builtin.assert:
        quiet: "{{ checklist.quiet }}"
        fail_msg: >-
          {{ keepalived_vip_svc }} is not a valid ip address.
        that:
          - (keepalived_vip_svc|ansible.builtin.ipaddr) != False
      delegate_to: localhost
      run_once: true
      when: keepalived_vip_svc

    - name: check if ip is the mgmt ip address.
      ansible.builtin.assert:
        quiet: "{{ checklist.quiet }}"
        fail_msg: >-
          {{ hostvars[inventory_hostname]['ip'] }} is not the management ip address.
        that:
          - hostvars[inventory_hostname]['ip'] == hostvars[inventory_hostname]['ansible_'+_mgmt_iface_name].ipv4.address
      vars:
        _mgmt_iface_name: "{% if ('pfmp' in groups and inventory_hostname in groups['pfmp']) %}{{ pfmp_mgmt_bridge_name }}{% else %}{{ mgmt_iface_name }}{% endif %}"
   
    - name: check if keepalived_vip is in management network range
      ansible.builtin.assert:
        quiet: "{{ checklist.quiet }}"
        fail_msg: >-
          {{ keepalived_vip }} is not in the management network.
        that:
          - ntp_allowed_cidr|ansible.utils.network_in_usable(keepalived_vip)
      delegate_to: localhost
      run_once: true
      when: inventory_hostname == groups['kube_control_plane'][0]

    - name: check if keepalived_vip_svc is in service network range
      ansible.builtin.assert:
        quiet: "{{ checklist.quiet }}"
        fail_msg: >-
          {{ keepalived_vip_svc }} is not in the service network.
        that:
          - svc_cidr|ansible.utils.network_in_usable(keepalived_vip_svc)
      when:
        - keepalived_vip_svc
        - inventory_hostname == groups['kube_control_plane'][0]

    - name: check overlay ip address is set if overlay_iface_name is not null
      ansible.builtin.assert:
        quiet: "{{ checklist.quiet }}"
        fail_msg: >-
          overlay_iface_name is not null.
          But ip address is not set up on overlay interface.
        that:
          - hostvars[inventory_hostname]['ansible_'+overlay_iface_name].ipv4.address is defined
      when:
        - overlay_iface_name
        - inventory_hostname in groups['k8s_cluster']

    - name: check if ip is not set on provider network interface
      ansible.builtin.assert:
        quiet: "{{ checklist.quiet }}"
        fail_msg: >-
          There should be no IPs on the provider network.
          But there is an IP address:
            {% if hostvars[inventory_hostname]['ansible_'+provider_iface_name].ipv4 is defined %}{{ hostvars[inventory_hostname]['ansible_'+provider_iface_name].ipv4.address }}{% endif %}
        that:
          - hostvars[inventory_hostname]['ansible_'+provider_iface_name].ipv4 is not defined
      when:
        - inventory_hostname in groups['k8s_cluster']

    - name: get time on deployer node
      ansible.builtin.set_fact:
        deployer_epoch: "{{ ansible_date_time.epoch }}"
      delegate_to: localhost
      run_once: true

    - name: check if time difference crosses the threshold
      ansible.builtin.assert:
        quiet: "{{ checklist.quiet }}"
        fail_msg: >-
          The time difference exceeds the threshold ({{ checklist.clock_deviation_threshold }}s).
          deployer time: {{ deployer_epoch }}
          my time: {{ ansible_date_time.epoch }}
        that:
          - (deployer_epoch|int - ansible_date_time.epoch|int)|abs < checklist.clock_deviation_threshold

    - name: check if osd block devices exist in osd nodes
      ansible.builtin.assert:
        quiet: "{{ checklist.quiet }}"
        fail_msg: >-
          Cannot find the device: {{ item.path }}
        that:
          - ansible_devices.{{ item.path|basename }} is defined
      loop: "{{ data_devices }}"
      when:
        - inventory_hostname in groups['osds']
        - not ceph_osd_use_all

    - name: check if osd block device has enough size.
      ansible.builtin.assert:
        quiet: "{{ checklist.quiet }}"
        fail_msg: >-
          {{ inventory_hostname }} does not have enough osd size.
          ({{ (ansible_devices[item.path|basename].sectors|int)*(ansible_devices[item.path|basename].sectorsize|int) }} < {{ (min_osd*(1024|pow(3))*0.9) }})
        that:
          - (ansible_devices[item.path|basename].sectors|int)*(ansible_devices[item.path|basename].sectorsize|int) >= (min_osd*(1024|pow(3))*0.9)
      loop: "{{ data_devices }}"
      when:
        - inventory_hostname in groups['osds']
        - not ceph_osd_use_all

    - name: check if network-node group is not empty
      ansible.builtin.assert:
        quiet: "{{ checklist.quiet }}"
        fail_msg: >-
          There is no hosts in network-node group.
        that:
          - groups['network-node']|length != 0
      delegate_to: localhost
      run_once: true

    - name: check if overlay interface is up if overlay is enabled.
      ansible.builtin.assert:
        quiet: "{{ checklist.quiet }}"
        fail_msg: >-
          {{ overlay_iface_name }} is not up.
        that:
          - hostvars[inventory_hostname]['ansible_'+overlay_iface_name].active
      when:
        - overlay_iface_name
        - inventory_hostname in groups['k8s_cluster']

    - name: check if all other interfaces are up on k8s nodes
      ansible.builtin.assert:
        quiet: "{{ checklist.quiet }}"
        fail_msg: >-
          {{ item }} is not up.
        that:
          - hostvars[inventory_hostname]['ansible_'+item].active
      loop:
        - "{{ svc_iface_name }}"
        - "{{ mgmt_iface_name }}"
        - "{{ provider_iface_name }}"
        - "{{ storage_iface_name }}"
      when: inventory_hostname in groups['k8s_cluster']

    - name: check storage ip address is set
      ansible.builtin.assert:
        quiet: "{{ checklist.quiet }}"
        fail_msg: >-
          IP address is not set up on storage interface.
        that:
          - hostvars[inventory_hostname]['ansible_'+storage_iface_name].ipv4.address is defined
      when: inventory_hostname in groups['k8s_cluster']

    - name: check storage ip addresses are set for powerflex storage
      ansible.builtin.assert:
        quiet: "{{ checklist.quiet }}"
        fail_msg: >-
          IP address on {{ item }} is not set up.
        that:
          - hostvars[inventory_hostname]['ansible_'+item].ipv4.address is defined
      loop: "{{ storage_iface_names }}"
      when:
        - "'powerflex' in storage_backends"
        - inventory_hostname in groups['powerflex']

    - name: check if powerflex sds devices exist in sds nodes
      ansible.builtin.assert:
        quiet: "{{ checklist.quiet }}"
        fail_msg: >-
          Cannot find the device: {{ item }}
        that:
          - ansible_devices[item|basename] is defined
      loop: "{{ sds_devices }}"
      when:
        - "'sds' in groups"
        - inventory_hostname in groups['sds']

    - name: check if powerflex sds device size is more than the minimum
      ansible.builtin.assert:
        quiet: "{{ checklist.quiet }}"
        fail_msg: >-
          SDS device ansible_devices.{{ item }} is too small.
          It should be more than {{ checklist.sds_device_min_size_in_mb }}MB.
        that:
          - ansible_devices[item].sectors|int*ansible_devices[item].sectorsize|int > checklist.sds_device_min_size_in_mb*1024*1024
          #- "{{ ansible_devices[item].sectors|int*ansible_devices[item].sectorsize|int > checklist.sds_device_min_size_in_mb*1024*1024 }}"
      loop: "{{ sds_devices|map('regex_replace', '^/dev/', '')|list }}"
      when:
        - "'sds' in groups"
        - inventory_hostname in groups['sds']

    - name: check if memory is enough to hold virtual machines in PFMP node
      ansible.builtin.assert:
        quiet: "{{ checklist.quiet }}"
        success_msg: >-
          The PFMP node has enough memory
          ({{ pfmp_memtotal }} MB >= {{ pfmp_minmem_threshold }} MB).
        fail_msg: >-
          The PFMP node does not have enough memory
          ({{ pfmp_memtotal }} MB < {{ pfmp_minmem_threshold }} MB)
        that:
          - (pfmp_memtotal|int) >= (pfmp_minmem_threshold|int)
      vars:
        pfmp_memtotal: "{{ ansible_facts['memtotal_mb'] }}"
        pfmp_minmem_threshold: "{{ ((pfmp_vm_spec['installer']['memory']+pfmp_vm_spec['mvm']['memory']*3+4)*1024) }}"
      when:
        - "'pfmp' in groups"
        - inventory_hostname in groups['pfmp']

    - name: check if disk is enough to hold virtual machines in PFMP node
      ansible.builtin.assert:
        quiet: "{{ checklist.quiet }}"
        success_msg: >-
          The PFMP node has enough disk space
          ({{ pfmp_disk_space }} GiB >= {{ pfmp_mindisk_threshold }} GiB).
        fail_msg: >-
          The PFMP node does not have enough disk space
          ({{ pfmp_disk_space }} GiB < {{ pfmp_mindisk_threshold }} GiB)
        that:
          - (pfmp_disk_space|int) >= (pfmp_mindisk_threshold|int)
      vars:
        pfmp_disk_space: "{{ ((ansible_facts['mounts']|selectattr('mount', 'equalto', '/')|list)[0].size_total/(1024|pow(3)))|round|int }}"
        pfmp_mindisk_threshold: "{{ (pfmp_vm_spec['installer']['disk']+pfmp_vm_spec['mvm']['disk']*3+30) }}"
        #pfmp_mindisk_threshold: "{{ (pfmp_vm_spec['installer']['disk']+pfmp_vm_spec['mvm']['disk']*3+30)*(1024|pow(3)) }}"
      when:
        - "'pfmp' in groups"
        - inventory_hostname in groups['pfmp']

    - name: check if purestorage api server is reachable
      ansible.builtin.uri:
        url: "https://{{ purestorage_mgmt_ip }}/"
        validate_certs: false
        timeout: 3
        status_code: 200
      when:
        - "'purestorage' in storage_backends"

    - name: check if netapp managementLIF is reachable
      ansible.builtin.uri:
        url: "https://{{ item.managementLIF }}/api/cluster?fields=version"
        url_username: "{{ item.username }}"
        url_password: "{{ item.password }}"
        validate_certs: false
        timeout: 3
        status_code: 200
      no_log: true
      loop: "{{ netapp }}"
      when:
        - "'netapp' in storage_backends"
        - inventory_hostname in groups['kube_node']

    - name: check if netapp dataLIF is reachable
      ansible.builtin.wait_for:
        host: "{{ item.dataLIF }}"
        port: 2049
        connect_timeout: 2
        sleep: 1
        timeout: 5
      loop: "{{ netapp }}"
      when:
        - "'netapp' in storage_backends"
        - inventory_hostname in groups['kube_node']

    - name: check if powerstore apiserver is reachable
      ansible.builtin.uri:
        url: "https://{{ item.apiserver }}/swaggerui/"
        validate_certs: false
        timeout: 3
        status_code: 200
      loop: "{{ powerstore }}"
      when:
        - "'powerstore' in storage_backends"
        - inventory_hostname in groups['kube_node']

    - name: check if powerstore nas host is reachable
      ansible.builtin.wait_for:
        host: "{{ item.nas_host }}"
        port: 2049
        connect_timeout: 2
        sleep: 1
        timeout: 5
      loop: "{{ powerstore }}"
      when:
        - "'powerstore' in storage_backends"
        - "'nas_host' in item"
        - inventory_hostname in groups['kube_node']

    - name: check if all hosts are reachable
      ansible.builtin.ping:
        data: pong
...
